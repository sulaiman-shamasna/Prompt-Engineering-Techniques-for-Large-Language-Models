{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guide to Prompt Engineering Techniques for Large Language Models\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "Prompt engineering is the process of designing natural language prompts to effectively extract desired information from large language models (LLMs) without retraining or fine-tuning them. With LLMs like GPT-3 and GPT-4 showing strong capabilities in many NLP tasks, prompt engineering has emerged as an essential practice to enhance their performance by leveraging their embedded knowledge. In this guide, we will cover key prompt engineering methods, each tailored for different types of NLP challenges, and support them with examples and code to demonstrate their effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Prompt Engineering?\n",
    "---\n",
    "\n",
    "Unlike traditional methods that require intensive retraining, prompt engineering enables LLMs to handle diverse tasks by modifying the way instructions are presented. Whether it's answering questions, performing logical reasoning, or solving mathematical problems, crafting an effective prompt can make a significant difference in model performance.\n",
    "\n",
    "Letâ€™s now explore several popular prompt engineering techniques in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Prompting\n",
    "---\n",
    "\n",
    "Basic prompting, also called \"vanilla prompting,\" involves providing a simple and direct instruction to the LLM to solve a given task. This is often the starting point for more advanced methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\__pycache__\\\\typing_extensions.cpython-38.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.50.2)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Collecting typing-extensions<5,>=4.11\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.6.1-cp38-none-win_amd64.whl (190 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.5.0-py3-none-any.whl (89 kB)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading pydantic_core-2.23.4-cp38-none-win_amd64.whl (1.9 MB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2.10)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Collecting exceptiongroup>=1.0.2; python_version < \"3.11\"\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, typing-extensions, pydantic-core, annotated-types, pydantic, exceptiongroup, anyio, h11, httpcore, httpx, distro, jiter, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1bc085fbdcbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbasic_prompt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Answer the following question: {question}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     response = openai.Completion.create(\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def basic_prompt(question):\n",
    "    prompt = f\"Answer the following question: {question}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Using the function to ask a question\n",
    "result = basic_prompt(\"What is the capital of France?\")\n",
    "print(result)  # Should output: \"Paris\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
